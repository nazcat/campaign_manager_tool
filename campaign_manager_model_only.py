import streamlit as st
import pandas as pd # version 2.0.3
import numpy as np
import plotly.express as px # version 5.15.0
import matplotlib.pyplot as plt # version 3.7.1
import matplotlib.ticker as mtick
import joblib
from sklearn.ensemble import RandomForestClassifier
from google.cloud import storage
from google.oauth2 import service_account
import io


# set up wide page on streamlit app
st.set_page_config(layout='wide', initial_sidebar_state='expanded')

##########################################
# load file for models from Google Cloud #
##########################################
# Load file anon_processed_unique_device_v3.csv from GCP

# Set up Google Cloud credentials using secrets stored in Streamlit Cloud
service_key = {
  "type": "service_account",
  "project_id": st.secrets['PROJECT_ID'],
  "private_key_id": st.secrets['PRIVATE_KEY_ID'],
  "private_key": st.secrets['PRIVATE_KEY'],
  "client_email": st.secrets['CLIENT_EMAIL'],
  "client_id": st.secrets['CLIENT_ID'],
  "auth_uri": st.secrets['AUTH_URI'],
  "token_uri": st.secrets['TOKEN_URI'],
  "auth_provider_x509_cert_url": st.secrets['AUTH_PROVIDER_URL'],
  "client_x509_cert_url": st.secrets['CLIENT_CERT_URL'],
  "universe_domain": "googleapis.com"
}

#Downloaded credentials in JSON format
project_id=service_key["project_id"]
credentials = service_account.Credentials.from_service_account_info(service_key)
client = storage.Client(project=project_id,credentials=credentials)

# Access the file in the bucket
bucket_name = 'campaign_manager_tool'
file_name = 'anon_processed_unique_device_v3.csv'
bucket = client.bucket(bucket_name)
blob = bucket.blob(file_name)

# Download the file content and read as a dataframe
content = blob.download_as_bytes()
anon_df = pd.read_csv(io.BytesIO(content))


############################
# Load Datasets for Models #
############################
@st.cache_data
def load_data():
    engagement_data = anon_df
    campaign_data = pd.read_csv('data/anan_campaign_modeling_data_v3.csv')
    return engagement_data, campaign_data

# Load Models for Prediction Tools
@st.cache_resource
def load_models():
    reg_model = joblib.load(r'models/regression_model.pkl')
    rf_classifier = joblib.load(r'models/rf_classifier.pkl')
    nn_model = joblib.load(r'models/nearest_neighbors_model.pkl')
    scaler = joblib.load(r'models/nearest_neighbors_scaler.pkl')
    return reg_model, rf_classifier, nn_model, scaler

# Preprocess Engagement Data
@st.cache_data
def preprocess_engagement_data(data):
    data['event_date'] = pd.to_datetime(data['event_date'].str[12:22])
    data['install_date'] = pd.to_datetime(data['install_date'].str[12:22])
    return data

# Load Data and Models
engagement_data, campaign_data = load_data()
engagement_data = preprocess_engagement_data(engagement_data)
reg_model, rf_classifier, nn_model, scaler = load_models()

# Columns for Genre Input
genre_columns = [
    "Classics", "Comedy", "Other", "Reality", "News and Information",
    "Drama", "Action & Adventure", "Thriller", "Sci-Fi & Fantasy", "Horror", "Western",
    "Documentaries", "Sports", "Instructional & Educational", "Home & Lifestyle", "Romance",
    "Anime", "Musical", "Independent", "Entertainment", "Paranormal", "Music", "Gay & Lesbian",
    "Crime", "Food & Cooking", "Faith & Spirituality", "Game Show", "Dance", "Children & Family",
    "Telenovela", "Talk Show", "Variety Show", "War", "Young Adult", "None"
]

#####################################
# Streamlit Setup and Sidebar Start #
#####################################
st.sidebar.header('')

# add date filter
st.sidebar.markdown('## Streaming Dates')
start_date = st.sidebar.date_input("Start Date", value=min(pd.to_datetime(totals['event_date'])))
end_date = st.sidebar.date_input("End Date", value=max(pd.to_datetime(totals['event_date'])))                               

# add multi select state filter
st.sidebar.markdown('## Choose Campaign')
all_campaigns = totals['campaign_name'].unique()
select_all_campaigns = st.sidebar.checkbox("Select All Campaigns", value=False)

if select_all_campaigns:
    campaign_select = all_campaigns
else:
    campaign_select = st.sidebar.multiselect(
        "Select State(s)", 
        options=all_campaigns, 
        default=["campaign_name_1"] if "campaign_name_1" in all_campaigns else []
    )
    
# add multi select state filter
st.sidebar.markdown('## Choose State')
all_states = totals['state'].unique()
select_all_states = st.sidebar.checkbox("Select All States", value=False)

if select_all_states:
    state_select = all_states
else:
    state_select = st.sidebar.multiselect(
        "Select State(s)", 
        options=all_states, 
        default=["MI"] if "MI" in all_states else []
    )

metric_options = ['Users', 'Minutes', 'Impressions', 'Clicks', 'Minutes per User']
metric_select = st.sidebar.selectbox("Select Metric", options=metric_options)


##############################################################
# Add Prediction Tools Section Below Existing Visualizations #
##############################################################
st.markdown("---")  # Separator for clarity
st.header("Predict Campaign Performance")
st.markdown("Test the performance of a theoretical or previously untested campaign that wasnâ€™t included in the training data using three insightful models. The first predicts the average watch time per device, the second forecasts the campaign score, and the third identifies the most similar campaign from the training data for comparison. For details on model accuracy and development, refer to the accompanying paper. The metric used here is average minutes watched per device.")

# Shared Inputs for Prediction Tools
impressions = st.number_input("Impressions", min_value=0)
clicks = st.number_input("Clicks", min_value=0)
genres = {genre: st.slider(genre, 0.0, 1.0) for genre in genre_columns}

# Radio button to select Prediction Tool
st.markdown("### Choose a Prediction Tool")
option = st.radio(
    "Select a tool:",
    ["Predict Watch Time", "Predict Campaign Score", "Most Similar Campaign"]
)

if option == "Predict Watch Time":
    if st.button("Predict Watch Time"):
        user_input = np.array([impressions, clicks] + list(genres.values())).reshape(1, -1)
        prediction = reg_model.predict(user_input)
        st.write(f"Predicted Average Watch Time per Device: {prediction[0]:.2f}")

elif option == "Predict Campaign Score":
    if st.button("Predict Campaign Score"):
        user_input = np.array([impressions, clicks] + list(genres.values())).reshape(1, -1)
        score_prediction = rf_classifier.predict(user_input)
        score_mapping = {0: 'Poor', 1: 'Fair', 2: 'Good', 3: 'Excellent'}
        st.write(f"Predicted Campaign Score: {score_mapping[score_prediction[0]]}")

elif option == "Most Similar Campaign":
    if st.button("Find Similar Campaign"):
        user_input = np.array([impressions, clicks] + list(genres.values())).reshape(1, -1)
        user_input_scaled = scaler.transform(user_input)

        # Find nearest campaign
        distances, indices = nn_model.kneighbors(user_input_scaled)
        similar_campaign = campaign_data.iloc[indices[0][0]]

        st.write("### Most Similar Campaign Details:")
        st.write(similar_campaign)

        # Downloadable CSV of the similar campaign
        csv = similar_campaign.to_frame().transpose().to_csv(index=False)
        st.download_button(
            label="Download Similar Campaign as CSV",
            data=csv,
            file_name='similar_campaign.csv',
            mime='text/csv'
        )
